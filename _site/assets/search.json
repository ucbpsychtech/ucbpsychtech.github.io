

[
  
  
    
    
      {
        "title": "Leveraging Big Data to Understand Emotion",
        "excerpt": "Alan Cowen grew up in Chicago and attended Yale University where he double majored in Cognitive Science\nand Applied Math. He graduated from the psychology graduate program at UC Berkeley where he studied \ncognitive neuroscience and social-personality. He was supervised by Prof. Dacher Keltner.\n\n",
        "content": "Alan Cowen grew up in Chicago and attended Yale University where he double majored in Cognitive Science\nand Applied Math. He graduated from the psychology graduate program at UC Berkeley where he studied \ncognitive neuroscience and social-personality. He was supervised by Prof. Dacher Keltner.\n\n\n  \n  Alan Cowen is a former graduate student who worked under the supervision of Prof. Dacher Keltner\n\n\nWhat drew you to study emotion?\n\nI’m interested in emotions because I believe they underlie everything we do. If we didn’t have feelings like restlessness, anxiety, or excitement, we wouldn’t get up in the morning. We’d have no basis upon which to evaluate our lives, we could only be apathetic. Emotions motivate every thought we have. Even when solving math problems, it is curiosity, the drive to succeed, or the threat of failure, that motivate us to move from one cognitive step to another.\n\nWhat is the goal of your research?\n\nMy goal has been to come up with a taxonomy of emotion, which means moving beyond reductive models like the six basic emotions and the affective circumplex. I’ve developed a new framework for taxonomies of emotion, with accompanying statistical tools, and used it to derive taxonomies of vocal expression, facial expression, the emotions evoked by music and video, and more.\n\nVocal Maps\n Facial Maps\n Music Maps\n Video Maps\n\nHow will your findings have real-world implications?\n\nI’ve helped big tech companies give people the tools to recognize and appropriately respond to their own and others’ emotions. Smartphone cameras now use information about people’s emotional expressions to optimize pictures, choosing the best frame out of a 300 or so millisecond window of time after you release the shutter in part based on whether it captures the right emotions in a given context. Mental illness researchers are using taxonomies of emotion to develop diagnostic tests of emotion recognition. Autism researchers are beginning to successfully use augmented reality devices to help patients attend to others’ emotions, which requires understanding what those emotions actually are. In theory, I think we could help people save their marriages, fix bad habits, and improve their people skills by addressing these problems at their emotional roots.\n\nFinally, what advances would you like to see in your field in the next two decades?\n\nI’m hoping that we can develop tools to accurately quantify people’s emotional behaviors in real time from video, audio, and language, in a context-sensitive way. Once we can do that, we can enter a world where computer models help us solve a vast array of human-centric problems. We could use algorithms that learn from millions of responses to buildings and cityscapes to evaluate or optimize architectural plans, for example, designing libraries that evoke awe, hospitals that make people feel safe, and so on. We could develop individualized assessments of mental illnesses. We could develop self-guided camera drones that take perfect wedding photos. There are a lot of possibilities. One of the ones that inspires me the most is the possibility to design machines that help vulnerable people who have difficulty recognizing or addressing their own emotional needs, infants, the elderly, people who struggle with severe mental illness, and so on, doing things as simple as changing the song or the channel when they aren’t enjoying themselves. That’s the kind of technology that could have helped my grandmother, who had severe Alzheimer’s, find enjoyable ways to spend her time even when people couldn’t be there to care for her.\n",
        "url": "/social-personality/cognitive%20neuroscience/emotion%20recognition/artificial%20intelligence/2019/07/13/Alan-Cowen/"
      },
    
      {
        "title": "AI has much to Learn From Childhood Curiosity",
        "excerpt": "Eliza Kosoy grew up in New York and attended Emmanuel College where she studied Mathematics. She then spent three years at MIT in the lab of Josh Tenenbaum. She is starting her second year in the psychology graduate program at UC Berkeley where she studies developmental psychology. She is supervised by Prof. Alison Gopnik.\n\n",
        "content": "Eliza Kosoy grew up in New York and attended Emmanuel College where she studied Mathematics. She then spent three years at MIT in the lab of Josh Tenenbaum. She is starting her second year in the psychology graduate program at UC Berkeley where she studies developmental psychology. She is supervised by Prof. Alison Gopnik.\n\n\n  \n  Eliza Kosoy is a second-year grad student working under the supervision of Prof. Alison Gopnik\n\n\nWhat drew you to study the intersection between child development and artificial intelligence (AI)?\n\nI have always loved working with children, I find it extremely fun and rewarding, kids have wonderful personalities and are extremely funny and insightful to me. It is nice to take a break from adults every now and then. I am also drawn to the interesting nature of AI research. I studied math for my undergraduate studies, and then spent some time in both a computational cognitive science lab and child development lab at MIT after undergrad which led me to where I am today.\n\nHow can children inform artifical intelligence algorithms?\n\nMy work attempts to understand how children learn novel concepts quickly and with little data in an effort to make more human-like machine learning algorithms. Recently I have been working with Deepak Pathak, Pulkit Agrawal and Alyosha Efros at BAIR (Berkeley Artificial Intelligence Research) on how to make AI more naturally curious. We are investigating intrinsic curiosity in children and how that might be beneficial in achieving goals. We use various environments originally created for testing AI agents for testing children on related tasks. I am also working on making an Omniglot JR. dataset that people can use for machine learning tasks which captures how children create and write novel letters by analyzing their stroke patterns. We also look at how well kids are at classifying novel letters in the Omniglot dataset. This is work I started at MIT working with Josh Tenenbaum, Brenden Lake and Laura Schulz.\n\nHow will your findings have real-world implications?\n\nAI has various applications for the world, ideally making certain mundane tasks more automated and thus freeing humans from certain kinds of work, perhaps we were not meant to be doing. Investigating the nature of curiously has potential for changing its purpose for people and maybe even encouraging everyone to be a bit more naturally curious.\n\nFinally, what advances would you like to see in your field in the next two decades?\n\nI would love to see an application in education where we could provide children all over the world with a low-cost personal teacher that helps them learn things faster based on their learning style and interests in the form of a tangible AI.\n",
        "url": "/developmental%20psychology/artificial%20intellignece/2019/07/13/Eliza-Kosoy/"
      },
    
      {
        "title": "Context is Crucial in Identifying Emotions",
        "excerpt": "Mandy Chen grew up in Zhongshan in southern China and attended Peking University in Beijing where she studied Psychology. \nShe is starting her fourth year in the psychology graduate program at UC Berkeley where she studies cognitive neuroscience. She \nis supervised by Prof. David Whitney.\n\n",
        "content": "Mandy Chen grew up in Zhongshan in southern China and attended Peking University in Beijing where she studied Psychology. \nShe is starting her fourth year in the psychology graduate program at UC Berkeley where she studies cognitive neuroscience. She \nis supervised by Prof. David Whitney.\n\n\n  \n  Mandy Chen is a fourth-year graduate student working under the supervision of Prof. David Whitney\n\n\nWhat drew you to study emotion perception?\n\nI have always had an interest in using quantitative methods to study mechanisms of the human mind. I was drawn to emotion perception because it is crucial for daily social interactions and it is a fascinating topic with a lot of gaps to fill. For example, one major advance in human object recognition is that we have taught computer vision models to recognize objects with amazing accuracy. However, recognizing emotion is a way more complex and challenging problem, and there have not been many successful models. I am hoping to bring some of the rigorous experimental techniques that I have learned in vision sciences (e.g. psychophysics) to help tackle this social science topic.\n\nWhat has your research uncovered about facial expressions?\n\nWhen it comes to reading a person’s state of mind, is it enough to just look at facial expressions? It is intuitive to say yes, and this has been the main direction of research for decades. However, my studies show that visual context – as in background and action – is both sufficient and necessary to accurately and rapidly recognize emotions. We blurred the faces and bodies of characters in muted video clips. Despite the characters’ invisible appearance, hundreds of participants were able to accurately read their emotions by extracting information from the visual context. We further show that the context provides a substantial and unique contribution beyond the information provided by the face and body. My research reveals that emotion recognition is, at its heart, an issue of context as much as faces.\n\nHow will your findings have real-world implications?\n\nCurrently, companies are developing machine learning models to recognize emotions, but they only train their models on cropped faces and these models can only read emotions from faces. My research shows that only looking at faces does not reveal emotions very accurately and models should consider the context as well. The method that I developed could be used to quantify the contribution of facial expression versus visual context in any video of any scenario. My findings can lead us to understand under what scenarios visual context is more important and what mechanism the brain employs to perform the inference.\n\nIn addition, current measures of emotional intelligence typically rely on decontextualized, oversimplified face stimuli. My findings suggest that tests of emotional intelligence will need to be revised to incorporate the separate but important issue of context. A person may be able to recognize static photos of facial emotions but fail to understand the displayed emotion accurately, unless they successfully incorporate the context. My method could eventually be used to evaluate how people with disorders like autism and schizophrenia recognize emotions in real time and help with their diagnoses.\n\nFinally, what advances would you like to see in your field in the next two decades?\n\nHigh-level cognitive functions such as emotion inference have been considered too difficult to solve in the field of computer vision, and very few artificial intelligence algorithms have succeeded in imitating them. I would like to see advances in the mechanisms underlying these high-level cognitive functions and hopefully build AI that can approach human abilities.\n",
        "url": "/cognitive%20neuroscience/artificial%20intelligence/emotion%20recognition/2019/07/13/Mandy-Chen/"
      },
    
      {
        "title": "Structural Forces at Play in Guiding Child Development",
        "excerpt": "Monica Ellwood-Lowe grew up in Milwaukee, Wisconsin and attended Stanford, where she majored in Psychology.\nShe is starting her third year in the psychology graduate program at UC Berkeley where she studies \ndevelopmental psychology. She is supervised by Profs. Mahesh Srinivasan and Silva Bunge.\n\n",
        "content": "Monica Ellwood-Lowe grew up in Milwaukee, Wisconsin and attended Stanford, where she majored in Psychology.\nShe is starting her third year in the psychology graduate program at UC Berkeley where she studies \ndevelopmental psychology. She is supervised by Profs. Mahesh Srinivasan and Silva Bunge.\n\n\n  \n  Monica Ellwood-Lowe is a third-year graduate student working under the joint supervision of Prof. Srinivasn and Prof. Bunge\n\n\nWhat drew you to developmental research?\n\nThe honest answer is some combination of interest and random chance. I stumbled into Professor Anne Fernald’s lab after taking an undergraduate seminar with her, and spent some of my most formative research years learning about language development from her and Dr. Virginia Marchman. Once you develop the kind of depth of knowledge in a topic that they helped me cultivate, it tends to follow you around. But what keeps me in developmental research is walking into kindergartens in Oakland and seeing kids’ bright eyes. It feels like a time when you can really make a difference in someone’s life.\n\nSome of your work thus far has explored how childhood environment (with a particular focus on SES) shapes important facets of cognitive development as well as brain development. What are some of your key findings?\n\nAs researchers who want to understand how the environment affects brain development, it’s tempting to simply split kids up according to whose parents are highly educated with well-paying jobs (high-SES) and whose parents are less so (low-SES) and measure behavioral and neural differences between them. Inevitably any difference you find will get translated and reported as a deficit for the low-SES kids. There are endless problems with this: What exactly are you measuring when you measure SES? What are the specific environmental mechanisms acting here? What are the structural constraints kids are up against, and who defines “optimal” outcomes? And, intriguingly for me, what are the benefits and trade-offs of different trajectories of brain development? It’s startling when you realize just how much of our knowledge about brain development comes from wealthy kids with highly educated parents who live near universities and have the time and resources to participate in research.\n\nIn some of my work, I’ve found that the volume of the hippocampus, a stress-sensitive region of the brain that is central to learning and memory, varies in size across adolescence in a different way for girls whose families make more or less money. For girls whose parents are wealthier, the hippocampus takes the trajectory of development that we are used to seeing in the literature, with a peak around age 18, followed by a plateau. But for girls whose parents are less wealthy, a different pattern emerges, with peak hippocampal volume seemingly appearing later on. Even more interestingly, this finding is independent of their mothers’ hippocampal size, suggesting that it is not mediated by genetic or potentially even shared environmental influences. This raises more questions than it answers. What do different trajectories of brain development mean for learning? What is the cause?\n\nIn ongoing work with Professors Silvia Bunge and Mahesh Srinivasan, I’m specifically measuring aspects of children’s home environment that we think might play a role in brain development, like the language surrounding a child during a typical day, and looking at how these relate to children’s attention, learning, and memory. I’m interested not in characterizing one set pattern of “optimal” development, but rather characterizing how development unfolds given the environmental context a child happens to grow up in. What is adaptive for one child given their context may be totally maladaptive for another. We can’t blindly assume the white upper-middle class context and developmental trajectory is optimal.\n\n\n  \n  Hippocampal volume in teenage girls is modulated by household income\n\n\nHow do you think your findings have the potential to inform public policy, education or early-life programs?\n\nFor one thing, if we accept the idea that children develop skills that best suit the demands of their environment—something which makes sense from an evolutionary perspective—it becomes very clear that schools typically start by building on the skills cultivated in higher-SES environments. Part of this is because there is less empirical research documenting the skills cultivated in lower-SES environments, a gap I’m hoping to fill with my research. And of course, part of this is because of the way schools have been purposefully structured in the first place.\n\nAt the same time, there is no question that being in an environment where you are systematically deprived of resources and opportunity for advancement has negative consequences. For example, in research that has been submitted for publication, Ruthe Foushee (another PhD student in the department), Professor Mahesh Srinivasan, and I have found evidence that financial constraints actually cause parents to talk less with their children. Even within a single family, we’ve found that parents talk less at the end of the month—when families are typically the most financially strapped—compared to the rest of the month. What is striking about this is that people tend to think of parenting as a skill that is stable within individuals, but simple fluctuations in external constraints seem to make a significant difference.\n\nI see this contributing to education and public policy in two ways: The first is that we need to stop thinking of development as having a clear pattern and instead think of it as an accumulating series of cognitive and biological tradeoffs. The second is that if we want lower-SES families to behave like higher-SES families, we need to be prepared to give them the external resources—financial and otherwise—that higher-SES families have.\n\nFinally, what advances would you like to see in your field in the next two decades?\n\nI’d like to see a more nuanced understanding of how variation in the environment leads to variation in the brain and behavior of children—with all its pros and cons—and how external constraints affect not only children but their parents and the ways their parents parent. Our focus is so often on individuals, but I’d like us to pay more attention to larger, structural forces at play.\n\nI would also like to see an integration of research on SES and development and research on racism and discrimination. Many people who study SES totally shy away from issues of race, which is bizarre when we consider the enormous racial wealth gap, and the fact that much of our present-day research on SES differences is actually rooted in historical research on supposed racial differences. In my view this is partly because the field of psychology, and cognitive neuroscience in particular, hasn’t figured out how to reconcile with its racist history; because biological determinism is still embedded in scientists’ collective beliefs even if their politics tell them not to say so out loud; and because there is a lack of shared understanding of the ways race has been constructed socially as opposed to biologically. It’s a tricky thing to study but I hope we can work together to try.\n\n",
        "url": "/developmental%20psychology/cognitive%20neuroscience/childhood%20inequality/language/2019/07/13/Monica-Ellwood-Lowe/"
      },
    
      {
        "title": " The Thrill of Doing Science is That We Don't Know What the Future Will Bring",
        "excerpt": "Alice Berners-Lee grew up in Lexington, Massachusetts and attended New York University where she majored in Neural Science and minored in Creative Writing. Alice started her PhD in 2014 at Johns Hopkins University in Baltimore under the supervision of Prof. David Foster. In 2017 the Foster lab was recruited to relocate to the University of California, Berkeley.\n\n",
        "content": "Alice Berners-Lee grew up in Lexington, Massachusetts and attended New York University where she majored in Neural Science and minored in Creative Writing. Alice started her PhD in 2014 at Johns Hopkins University in Baltimore under the supervision of Prof. David Foster. In 2017 the Foster lab was recruited to relocate to the University of California, Berkeley.\n\n\n  \n  Alice Berners-Lee is a fifth year grad student working under the supervision of Prof. David Foster\n\n\nWhat have you learned about how the brain represents spatial information?\n\nWhen an animal runs around, neurons in a particular area of the brain called the hippocampus tell the animal where it is in space. This means that as experimentalists, if we record from enough of these neurons, we could close our eyes and know pretty well where the animal is, just from the brain’s activity. Because we’re deciphering the brain’s code—the meaning of the electrical pulses that neurons use to communicate with each other—we call this procedure “decoding.” One of the most exciting parts of my research is that scientists have been studying this particular neural code—how the hippocampus represents space—for decades, so we understand it remarkably well. That foundation, combined with the particularities of hippocampal anatomy which allow us to record from many neurons simultaneously, means we can decode the brain’s activity with very high accuracy, to the point that you could call it a kind of mind-reading. When the animal is not running around but is standing still (often grooming or eating), these neurons fire seemingly all at once. What we see when we zoom in on these bursts of activity still amazes me: even though the animal is stationary, the hippocampus is actually playing out trajectories through space, at twenty times the speed at which the animal actually moved through the space. This phenomenon, called “replay,” is what I’ve been studying for the last four years of my PhD. \nReplay was first discovered during sleep and was initially posited to support long-term memory and learning. Subsequent studies found that replays also occur when the animal is awake, and that the trajectories depicted by these replay events tend to extend from the animal’s current position to the location of a reward, making them a candidate mechanism for “online” planning as well. Additionally, when there is a change in the environmental layout of rewards, replays reflect those changes, implicating them in learning where rewards are. \nBut in order for replays to inform the behavior of the animal, they will have to be heard and processed by other areas in the brain such as areas that control an animal’s choices or movement. In learning what aspects of replay matter to downstream areas that receive that information, we also learn more about which aspects matter for the function of replay. I think the question of how replays in the hippocampus engage the rest of the brain is so interesting and important that I decided to focus on it for my PhD. If we can understand how hippocampal replay interacts with the whole brain, and how that changes across experience and learning, we can better understand the mechanisms and function of mental exploration.\n\nHow will your work have real-world implications?\n\nOne of the most promising applications for the knowledge we uncover about replay is in mental illnesses such as schizophrenia. In mice genetically engineered to have something like schizophrenia, their hippocampal neurons behave abnormally. The neurons “burst” (fire off a handful of electrical pulses in quick succession) more than usual, but their bursts of activity don’t contain ordered replay—instead, the activity appears chaotic and uninterpretable. This deficit in replay is accompanied with deficits in social interaction, locomotor activity and working memory. Because there is still so much to be understood about replay in the typical brain state, we are far from understanding when and how replays get corrupted in disease and dysfunction. However, because replays have been shown to be important for memory and implicated in decision-making, investigating the mechanisms and functions of replay could help us understand more complex aspects of disease states.\n\nFinally, what advances would you like to see in your field in the next two decades?\n\nOne of the most exciting advances in hippocampal replay is being able to detect these sequences online and be able to causally manipulate their trajectories. There are a lot of exciting hypotheses about why our brains replay information during sleep and awake rest, and causal manipulations are the gold standard to test these hypotheses. For example, when a rat learns to navigate to a hidden reward in a large environment, its replays tend to take trajectories towards that remembered goal location. This implies that replays may be guiding the rat’s subsequent behavior, but we can’t be sure. In order to test the effect of these replays on behavior, we need to decode the neurons’ activity as the animal performs the task, allowing us to interrupt the replays that would be headed to the goal. Then, if the rat isn’t able to navigate to that goal location, we would have more confidence that replays were guiding the rat’s behavior. Another advance I hope to see is to use newly invented recording equipment to investigate whether replay occurs in brain regions outside of the hippocampus. Until recently, technical difficulties in recording from enough neurons simultaneously prevented those experiments. Of course, the thrill of doing science is that we don’t know what the future will bring. It’s exciting to be in such a young field with so many emerging tools and unanswered questions.\n\n",
        "url": "/behavior%20and%20systems%20neuroscience/cognitive%20neuroscience/memory/2019/08/07/Alice-Berners-Lee/"
      },
    
      {
        "title": "Listen to Your Heart: What Cardiovascular Health Can Teach Us About Sleep",
        "excerpt": "Vyoma Shah grew up in Mumbai, India and attended UC Berkeley where she majored in cognitive science. She is starting her third year in the psychology graduate program at Berkeley where she studies cognitive neuroscience. She is supervised by Prof. Matt Walker.\n\n",
        "content": "Vyoma Shah grew up in Mumbai, India and attended UC Berkeley where she majored in cognitive science. She is starting her third year in the psychology graduate program at Berkeley where she studies cognitive neuroscience. She is supervised by Prof. Matt Walker.\n\n\n  \n  Vyoma Shah is a third-year graduate student working under the supervision of Prof. Matt Walker\n\n\nWhat drew you to study cognitive neuroscience?\n\nI remember the first time I saw a real human brain and being amazed at how a 3 lbs. piece of flesh could produce the wondrous capabilities it does, from controlling my muscle movements, to allowing me to ponder my place in the universe. I increasingly found myself drawn to reading neuroscience/psychology blogs and articles during my free time, and I gradually developed a deep passion to better understand the workings of the brain. I’ve always wanted to pursue a clinical career that would have the potential to make a meaningful healthcare-related difference in the world. My current line of research is aimed at better understanding the relationship between sleep and cardiovascular health, and how these links change in old age.\n\nWhat have you learned about the relationship between sleep and cardiovascular health in aging?\n\nWe know that different stages of sleep are associated with different forms of cardiac control. For example, the deepest stage of sleep is associated with high parasympathetic modulation and the lowest blood pressure in a 24-hour cycle. We also know that the composition of sleep itself is altered in aging; older adults get worse sleep. Currently, we are using different measures of cerebro and cardiovascular health (e.g. blood pressure, heart rate variability at rest and at stress, and brain white matter lesion volume) to investigate how each of them are linked to sleep quality and/or quantity, in young versus older adults.\n\n\n  \n  Vyoma’s research focuses on the relationship between sleep and cardiovascular health over the lifespan.\n\n\nHow will your findings have real-world implications?\n\nCardiovascular disease is currently the leading cause of death in the world. Improving sleep quality and quantity can both alleviate negative cardiovascular risk factors (e.g. lower blood pressure) and improve positive cardiovascular health factors (e.g. increase heart rate variability). Relative to many other risk factors in aging, sleep stands out as a modifiable factor (via interventions to improve sleep), and to reduce the risk of cardiovascular diseases such as stroke, heart attack, cardiac attack, etc. This has tremendous implications for quality of life, public health, and cost of healthcare in the real world.\n\nFinally, what advances would you like to see in your field in the next two decades?\n\nThere is currently fairly good awareness of three crucial pillars of actively maintaining good health: food, exercise and sleep. Currently, most people don’t immediately associate cardiovascular disease (e.g. heart attack, stroke, cardiac arrest) with sleep at all. Compare this to the regular association of heart health and food/exercise! My broad hope for the next few years is two-fold: 1) an increased awareness of the deep and strong bidirectional association between sleep and cardiovascular health, and 2) progress in the development of interventions to improve sleep, and subsequently, cardiovascular health.\n\n",
        "url": "/cognitive%20neuroscience/sleep/cardiovascular%20health/aging/2019/09/03/Vyoma-Shah/"
      },
    
  
  
  
  {
    "title": "About Us",
    "excerpt": "\n",
    "content": "This site is powered by PhD students in the Department of Psychology at UC Berkeley. We are a diverse group of students studying cognition, social-personality, development, clinical science, cognitive and behavioural neuroscience. Our interests range from basic circuit-level neurobiology to sleep to developmental disorders.\n\nWe are conducting great research that has wide appeal to a broad audience. We want to disseminate our findings and ideas in a way that is accessible and engaging to everyone!\n\nWe update this page regularly with graduate student spotlights and opinion pieces contributed by psychology graduate students in the department.\n\nIf you would like to contribute to this collaborative effort or if you have any questions, please contact maedbhking@berkeley.edu.\n",
    "url": "/about/"
  },
  
  {
    "title": "Categories",
    "excerpt": "Category index\n",
    "content": "\n",
    "url": "/categories/"
  },
  
  {
    "title": "Contact Us",
    "excerpt": "\n",
    "content": "Please send us a message using the form below\n\n\n  \n    Contact\n    Name: *\n    \n\n    Email Address: *\n    \n\n    Message: *\n    \n\n    \n    \n    * indicates a required field\n\n    \n      \n      \n      \n    \n  \n\n\n\n\nPlease enable JavaScript to use the form.\n\n",
    "url": "/contact/"
  },
  
  {
    "title": "Donate",
    "excerpt": "\n",
    "content": "nothing yet\n",
    "url": "/donate/"
  },
  
  {
    "title": "Spotlights",
    "excerpt": "\n",
    "content": "\n",
    "url": "/spotlights/"
  },
  
  {
    "title": "Outreach",
    "excerpt": "\n",
    "content": "Under Construction\n",
    "url": "/outreach/"
  },
  
  {
    "title": "Thanks!",
    "excerpt": "\n",
    "content": "Thank you for messaging us! We will get back to you soon.\n",
    "url": "/thanks/"
  },
  
  {
    "title": "Spotlights",
    "excerpt": "\n",
    "content": "\n",
    "url": "/spotlights/page2/"
  }
  
]

